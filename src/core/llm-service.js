const { GoogleGenerativeAI } = require('@google/generative-ai');
const config = require('../config/env');

// Heuristic nhanh khi LLM l·ªói ho·∫∑c ch·∫≠m
function heuristicIntent(question) {
    const text = (question || '').toLowerCase();
    const createKeywords = ['t·∫°o d·ª± √°n', 'tao du an', 't·∫°o project', 'create project', 'du an moi', 'd·ª± √°n m·ªõi'];
    if (createKeywords.some(k => text.includes(k))) {
        return 'create_project';
    }
    return 'NO_TOOL';
}

let model;
function getModel() {
    if (!config.GEMINI_API_KEY) {
        throw new Error('GEMINI_API_KEY is missing. Set it in the environment before starting the server.');
    }
    if (!model) {
        const genAI = new GoogleGenerativeAI(config.GEMINI_API_KEY);
        model = genAI.getGenerativeModel({ model: config.GEMINI_MODEL });
    }
    return model;
}

class LLMService {
    /**
     * Ph√¢n t√≠ch √Ω ƒë·ªãnh ng∆∞·ªùi d√πng v√† tr√≠ch xu·∫•t th√¥ng tin
     */
    async analyzeIntent(question, currentSession, history) {
        console.log(`üîç AI Analyzing: "${question}"`);

        // Format l·ªãch s·ª≠ chat
        let historyContext = "";
        if (history && history.length > 0) {
            historyContext = "--- Conversation History ---\n" +
                history.map(m => `[${m.role}]: ${m.content}`).join('\n') +
                "\n----------------------------\n";
        }

        const prompt = `
        B·∫°n l√† tr·ª£ l√Ω AI qu·∫£n l√Ω d·ª± √°n (Orchestrator Agent).
        Nhi·ªám v·ª•: Tr√≠ch xu·∫•t th√¥ng tin M·ªöI t·ª´ c√¢u n√≥i ng∆∞·ªùi d√πng ƒë·ªÉ ƒëi·ªÅn v√†o form ho·∫∑c x√°c ƒë·ªãnh Tool c·∫ßn g·ªçi.

        === TR·∫†NG TH√ÅI HI·ªÜN T·∫†I (Session Context) ===
        ${JSON.stringify(currentSession)}

        === C√ÅC TOOL H·ªñ TR·ª¢ ===
        1. create_project: T·∫°o d·ª± √°n m·ªõi.
           - Params c·∫ßn: company_id, workspace_id, name, code, start_date, end_date, priority, description.
        2. ask_knowledge: H·ªèi v·ªÅ quy tr√¨nh, t√†i li·ªáu (RAG).
           - Params: query (c√¢u h·ªèi c·ªßa user).

        === QUY T·∫ÆC ===
        1. **Context Memory:** ƒê·ªçc k·ªπ History. N·∫øu th√¥ng tin ƒë√£ c√≥, gi·ªØ nguy√™n.
        2. **Map Name:** N·∫øu user nh·∫≠p t√™n (vd "TechVision"), ƒëi·ªÅn v√†o field ID t∆∞∆°ng ·ª©ng (System s·∫Ω t·ª± map).
        3. **Short Answer:** N·∫øu System v·ª´a h·ªèi "Ch·ªçn Workspace n√†o?" v√† user ƒë√°p "ABC", hi·ªÉu l√† workspace_id = "ABC".
        4. **Routing:** N·∫øu c√¢u h·ªèi v·ªÅ ki·∫øn th·ª©c (vd "Quy tr√¨nh ngh·ªâ ph√©p"), tr·∫£ v·ªÅ action "ask_knowledge".

        Input: "${question}"
        ${historyContext}

        Tr·∫£ v·ªÅ JSON duy nh·∫•t: { "action": "create_project" | "ask_knowledge" | "NO_TOOL", "params": { ... } }
        `;

        try {
            const result = await getModel().generateContent(prompt);
            const text = result.response.text();

            // --- S·ª¨A L·ªñI: X·ª≠ l√Ω chu·ªói JSON an to√†n ---
            // T√¨m chu·ªói JSON trong c·∫∑p d·∫•u ```json ... ``` ho·∫∑c l·∫•y to√†n b·ªô text n·∫øu kh√¥ng c√≥ markdown
            const match = text.match(/```json\s*([\s\S]*?)\s*```/);
            const jsonStr = match ? match[1] : text;
            // ----------------------------------------

            return JSON.parse(jsonStr);
        } catch (e) {
            console.error("‚ùå Gemini Analysis Error:", e.message);
            // Fallback an to√†n: d√πng heuristic ƒë·ªÉ c·ªë g·∫Øng ch·ªçn tool h·ª£p l√Ω
            return { action: heuristicIntent(question), params: {} };
        }
    }

    /**
     * Sinh c√¢u tr·∫£ l·ªùi cu·ªëi c√πng cho ng∆∞·ªùi d√πng
     */
    async generateResponse(question, systemResult) {
        const prompt = `
        User h·ªèi: "${question}"
        K·∫øt qu·∫£ h·ªá th·ªëng th·ª±c hi·ªán (JSON): ${JSON.stringify(systemResult)}

        Vi·∫øt c√¢u tr·∫£ l·ªùi ti·∫øng Vi·ªát, ng·∫Øn g·ªçn, th√¢n thi·ªán, d·∫°ng m√¥ t·∫£ d·ªÖ ƒë·ªçc.
        ∆Øu ti√™n li·ªát k√™ th√¥ng tin ch√≠nh (T√™n d·ª± √°n, M√£, C√¥ng ty, Workspace, Ng√†y b·∫Øt ƒë·∫ßu/k·∫øt th√∫c, ID) b·∫±ng c√¢u t·ª± nhi√™n.
        KH√îNG tr·∫£ v·ªÅ JSON, KH√îNG d√πng markdown, kh√¥ng g√≥i trong code block.
        `;
        try {
            const result = await getModel().generateContent(prompt);
            return result.response.text();
        } catch (e) {
            return JSON.stringify(systemResult);
        }
    }

    /**
     * Sinh c√¢u h·ªèi b·ªï sung ƒë·ªÉ l·∫•y c√°c tr∆∞·ªùng c√≤n thi·∫øu
     */
    async generateFollowup(missingFields = [], sessionSnapshot = {}) {
        const prompt = `
        B·∫°n l√† tr·ª£ l√Ω AI ƒëang thu th·∫≠p th√¥ng tin ƒë·ªÉ t·∫°o d·ª± √°n.
        C√°c tr∆∞·ªùng c√≤n thi·∫øu: ${missingFields.join(', ')}.
        Ng·ªØ c·∫£nh hi·ªán c√≥: ${JSON.stringify(sessionSnapshot)}.
        Vi·∫øt c√¢u h·ªèi ti·∫øng Vi·ªát t·ª± nhi√™n, th√¢n thi·ªán, ng·∫Øn g·ªçn (gi·ªçng chat).
        N·∫øu thi·∫øu nhi·ªÅu tr∆∞·ªùng, g·ªôp h·ªèi trong 1-2 c√¢u, tr√°nh li·ªát k√™ kh√¥ khan.
        Tr√°nh m·ªánh l·ªánh "vui l√≤ng/please", ch·ªâ h·ªèi nh∆∞ h·ªôi tho·∫°i b√¨nh th∆∞·ªùng.
        `;
        try {
            const result = await getModel().generateContent(prompt);
            return result.response.text();
        } catch (e) {
            // Fallback: chu·ªói tƒ©nh
            return `M√¨nh c·∫ßn th√™m th√¥ng tin: ${missingFields.join(', ')}. B·∫°n b·ªï sung gi√∫p nh√©?`;
        }
    }
}

module.exports = new LLMService();
